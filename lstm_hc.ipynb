{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "from time import gmtime, strftime, time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import TPScoringFunction, calc_auc, ecfp, score\n",
    "\n",
    "def timestamp():\n",
    "    return strftime(\"%Y-%m-%d_%H:%M:%S\", gmtime())\n",
    "\n",
    "def fit_clfs(chid, n_estimators, n_jobs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        chid: which assay to use:\n",
    "        external_file:\n",
    "    \"\"\"\n",
    "    # read data and calculate ecfp fingerprints\n",
    "    assay_file = f'./assays/processed/{chid}.csv'\n",
    "    print(f'Reading data from: {assay_file}')\n",
    "    df = pd.read_csv(assay_file)\n",
    "    X = np.array(ecfp(df.smiles))\n",
    "    y = np.array(df.label)\n",
    "\n",
    "    # split in equally sized sets. Stratify to get same label distributions\n",
    "    X1, X2, y1, y2 = train_test_split(X, y, test_size=0.5, stratify=y)\n",
    "\n",
    "    balance = (np.mean(y1), np.mean(y2))\n",
    "\n",
    "    # train classifiers and store them in dictionary\n",
    "    clfs = {}\n",
    "    clfs['Split1'] = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, n_jobs=n_jobs)\n",
    "    clfs['Split1'].fit(X1, y1)\n",
    "\n",
    "    clfs['Split1_alt'] = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, n_jobs=n_jobs)\n",
    "    clfs['Split1_alt'].fit(X1, y1)\n",
    "\n",
    "    clfs['Split2'] = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, n_jobs=n_jobs)\n",
    "    clfs['Split2'].fit(X2, y2)\n",
    "\n",
    "    # calculate AUCs for the clfs\n",
    "    aucs = {}\n",
    "    aucs['Split1'] = calc_auc(clfs['Split1'], X2, y2)\n",
    "    aucs['Split1_alt'] = calc_auc(clfs['Split1_alt'], X2, y2)\n",
    "    aucs['Split2'] = calc_auc(clfs['Split2'], X1, y1)\n",
    "    print(\"AUCs:\")\n",
    "    for k, v in aucs.items():\n",
    "        print(f'{k}: {v}')\n",
    "\n",
    "    return clfs, aucs, balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: ./assays/processed/CHEMBL3888429.csv\n",
      "AUCs:\n",
      "Split1: 0.8218614718614718\n",
      "Split1_alt: 0.8124458874458874\n",
      "Split2: 0.8033948940793046\n"
     ]
    }
   ],
   "source": [
    "# def optimize(chid,\n",
    "#              n_estimators,\n",
    "#              n_jobs,\n",
    "#              external_file,\n",
    "#              n_external,\n",
    "#              seed,\n",
    "#              optimizer_args):\n",
    "\n",
    "\n",
    "chid='CHEMBL3888429'\n",
    "n_estimators=100\n",
    "n_jobs=8\n",
    "external_file='./data/guacamol_v1_test.smiles.can'\n",
    "n_external=3000\n",
    "seed=101\n",
    "\n",
    "    \n",
    "np.random.seed(seed)\n",
    "# config = locals()\n",
    "# print(locals())\n",
    "#set up logging\n",
    "results_dir = os.path.join('./test', 'graph_ga', chid, timestamp())\n",
    "os.makedirs(results_dir)\n",
    "\n",
    "# config_file = os.path.join(results_dir, 'config.json')\n",
    "# with open(config_file, 'w') as f:\n",
    "#     json.dump(config, f)\n",
    "\n",
    "\n",
    "\n",
    "clfs, aucs, balance = fit_clfs(chid, n_estimators, n_jobs)\n",
    "results = {}\n",
    "results['AUC'] = aucs\n",
    "results['balance'] = balance\n",
    "\n",
    "clf_file = os.path.join(results_dir, 'classifiers.p')\n",
    "with open(clf_file, 'wb') as f:\n",
    "    pickle.dump(clfs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained_model_path = 'hi',\n",
      "n_epochs = 4,\n",
      "mols_to_sample = 1028,\n",
      "keep_top = 512,\n",
      "optimize_n_epochs = 2,\n",
      "max_len = 100,\n",
      "optimize_batch_size = 64,\n",
      "number_final_samples = 1028,\n",
      "sample_final_model_only = False,\n",
      "random_start = False,\n",
      "smi_file = None,\n",
      "n_jobs = -1,\n"
     ]
    }
   ],
   "source": [
    "for k, v in optimizer_args.items():\n",
    "    print(f'{k} = {repr(v)},')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting initial population...\n"
     ]
    }
   ],
   "source": [
    "from generators import GB_GA_Generator, SmilesRnnDirectedGenerator\n",
    "\n",
    "# Create guacamol scoring function with clf trained on split 1\n",
    "scoring_function = TPScoringFunction(clfs['Split1'])\n",
    "\n",
    "optimizer_args = dict(pretrained_model_path = './guacamol_baselines/smiles_lstm_hc/pretrained_model/model_final_0.473.pt',\n",
    "                        n_epochs = 4,\n",
    "                        mols_to_sample = 1028,\n",
    "                        keep_top = 512,\n",
    "                        optimize_n_epochs = 2,\n",
    "                        max_len = 100,\n",
    "                        optimize_batch_size = 64,\n",
    "                        number_final_samples = 1028,\n",
    "                        sample_final_model_only = False,\n",
    "                        random_start = True,\n",
    "                        smi_file = './data/guacamol_v1_train.smiles.can',\n",
    "                        n_jobs = -1,\n",
    "                        canonicalize=False)\n",
    "\n",
    "# run optimization\n",
    "t0 = time()\n",
    "optimizer = SmilesRnnDirectedGenerator(**optimizer_args)\n",
    "smiles_history = optimizer.generate_optimized_molecules(scoring_function, 100, get_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smiles_history)\n",
    "\n",
    "'abcccc' < 'bcc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of dictionaries for every time step\n",
    "statistics = []\n",
    "for optimized_smiles in smiles_history:\n",
    "    row = {}\n",
    "    row['smiles'] = optimized_smiles\n",
    "    row['preds'] = {}\n",
    "    row['ratio_active'] = {}\n",
    "    row['mean_pred'] = {}\n",
    "    for k, clf in clfs.items():\n",
    "        preds = score(optimized_smiles, clf)\n",
    "        row['preds'][k] = preds\n",
    "    statistics.append(row)\n",
    "\n",
    "results['statistics'] = statistics\n",
    "\n",
    "stat_time = time() - t1\n",
    "# add predictions on external set\n",
    "# load external smiles for evaluation\n",
    "with open(external_file) as f:\n",
    "    external_smiles = f.read().split()\n",
    "external_smiles = np.random.choice(external_smiles, n_external)\n",
    "results['predictions_external'] = {k: score(external_smiles, clf) for k, clf in clfs.items()}\n",
    "\n",
    "results_file = os.path.join(results_dir, 'results.json')\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "print(f'Storing results in {results_dir}')\n",
    "print(f'Optimization time {opt_time:.2f}')\n",
    "print(f'Statistics time {stat_time:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Goal-directed generation benchmark for SMILES RNN',\n",
    "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('--model_path', default=None, help='Full path to the pre-trained SMILES RNN model')\n",
    "parser.add_argument('--max_len', default=100, type=int, help='Max length of a SMILES string')\n",
    "parser.add_argument('--seed', default=42, type=int, help='Random seed')\n",
    "parser.add_argument('--output_dir', default=None, help='Output directory for results')\n",
    "parser.add_argument('--number_repetitions', default=1, type=int, help='Number of re-training runs to average')\n",
    "parser.add_argument('--keep_top', default=512, type=int, help='Molecules kept each step')\n",
    "parser.add_argument('--n_epochs', default=20, type=int, help='Epochs to sample')\n",
    "parser.add_argument('--mols_to_sample', default=1024, type=int, help='Molecules sampled at each step')\n",
    "parser.add_argument('--optimize_batch_size', default=256, type=int, help='Batch size for the optimization')\n",
    "parser.add_argument('--optimize_n_epochs', default=2, type=int, help='Number of epochs for the optimization')\n",
    "parser.add_argument('--benchmark_num_samples', default=4096, type=int,\n",
    "                    help='Number of molecules to generate from final model for the benchmark')\n",
    "parser.add_argument('--benchmark_trajectory', action='store_true',\n",
    "                    help='Take molecules generated during re-training into account for the benchmark')\n",
    "parser.add_argument('--smiles_file', default='data/guacamol_v1_all.smiles')\n",
    "parser.add_argument('--random_start', action='store_true')\n",
    "parser.add_argument('--n_jobs', type=int, default=-1)\n",
    "parser.add_argument('--suite', default='v2')\n",
    "\n",
    "args = parser.parse_args('')\n",
    "for k,v in args.__dict__.items():\n",
    "    print(f'{k} = {v},')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guacamol",
   "language": "python",
   "name": "guacamol"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
